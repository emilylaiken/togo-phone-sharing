{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import *\n",
    "from functools import reduce\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from linearmodels.panel import PanelOLS\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "from utils import *\n",
    "\n",
    "spark = get_spark_session()\n",
    "sns.set(font_scale=2, style='white')\n",
    "\n",
    "def simpleaxis(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as infile:\n",
    "    config = json.load(infile)\n",
    "indir = config['indir']\n",
    "outdir = config['outdir']\n",
    "admin_fname = config['admin_fname']\n",
    "canton_assignment_fname = config['cantons_assignment_fname']\n",
    "rct_assignment_fname = config['rct_assignment_fname']\n",
    "shapefile_fname = config['shapefile_fname']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Plot unique MSISDN and IMEIs by day, remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplevel_dir = outdir + 'january/'\n",
    "months = ['2021-01']\n",
    "\n",
    "cols = ['caller_msisdn', 'operator', 'month', 'day', 'imei']\n",
    "voice = spark.read.csv(indir + 'voice/2021/1.csv', header=True)\\\n",
    "    .select(cols)\\\n",
    "    .where(col('month').isin(months))\\\n",
    "    .na.drop(subset=['caller_msisdn', 'month', 'day', 'imei'])\n",
    "sms = spark.read.csv(indir + 'sms/2021/1.csv', header=True)\\\n",
    "    .select(cols)\\\n",
    "    .where(col('month').isin(months))\\\n",
    "    .na.drop(subset=['caller_msisdn', 'month', 'day', 'imei'])\n",
    "cdr = voice.union(sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msisdn_by_day = cdr.groupby('day').agg(countDistinct('caller_msisdn'))\\\n",
    "    .withColumnRenamed('count(caller_msisdn)', 'count')\n",
    "save_df(msisdn_by_day, toplevel_dir + 'msisdn_by_day.csv')\n",
    "\n",
    "imei_by_day = cdr.groupby('day').agg(countDistinct('imei'))\\\n",
    "    .withColumnRenamed('count(imei)', 'count')\n",
    "save_df(imei_by_day, toplevel_dir + 'imei_by_day.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msisdn_by_day = pd.read_csv(toplevel_dir + 'msisdn_by_day.csv')\n",
    "msisdn_by_day['day'] = pd.to_datetime(msisdn_by_day['day'])\n",
    "msisdn_by_day = msisdn_by_day.sort_values('day', ascending=True)\n",
    "\n",
    "imei_by_day = pd.read_csv(toplevel_dir + 'imei_by_day.csv')\n",
    "imei_by_day['day'] = pd.to_datetime(imei_by_day['day'])\n",
    "imei_by_day = imei_by_day.sort_values('day', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "ax[0].scatter(msisdn_by_day['day'], msisdn_by_day['count']/1000000, color='indianred')\n",
    "ax[0].plot(msisdn_by_day['day'], msisdn_by_day['count']/1000000, color='indianred')\n",
    "ax[0].set_title('MSISDNs by Day')\n",
    "ax[0].set_ylabel('MSISDNs (millions)')\n",
    "msisdn_sd_below = msisdn_by_day['count'].mean() - 2*msisdn_by_day['count'].std()\n",
    "msisdn_sd_above = msisdn_by_day['count'].mean() + 2*msisdn_by_day['count'].std()\n",
    "ax[0].axhline(msisdn_sd_above/1000000, color='grey', dashes=[1, 1])\n",
    "ax[0].axhline(msisdn_sd_below/1000000, color='grey', dashes=[1, 1])\n",
    "\n",
    "ax[1].scatter(imei_by_day['day'], imei_by_day['count']/1000000, color='mediumseagreen')\n",
    "ax[1].plot(imei_by_day['day'], imei_by_day['count']/1000000, color='mediumseagreen')\n",
    "ax[1].set_title('IMEIs by Day')\n",
    "ax[1].set_ylabel('IMEIs (millions)')\n",
    "imei_sd_below = imei_by_day['count'].mean() - 2*imei_by_day['count'].std()\n",
    "imei_sd_above = imei_by_day['count'].mean() + 2*imei_by_day['count'].std()\n",
    "ax[1].axhline(imei_sd_below/1000000, color='grey', dashes=[1, 1])\n",
    "ax[1].axhline(imei_sd_above/1000000, color='grey', dashes=[1, 1])\n",
    "\n",
    "locator = mdates.DayLocator(interval=7)\n",
    "formatter = mdates.DateFormatter('%m-%d')\n",
    "for a in range(len(ax)):\n",
    "    ax[a].xaxis.set_major_locator(locator)\n",
    "    ax[a].xaxis.set_major_formatter(formatter)\n",
    "    simpleaxis(ax[a])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "outliers_msisdn = list(msisdn_by_day[(msisdn_by_day['count'] < msisdn_sd_below) | \\\n",
    "                                     (msisdn_by_day['count'] > msisdn_sd_above)]['day'])\n",
    "outliers_imei = list(msisdn_by_day[(msisdn_by_day['count'] < msisdn_sd_below) | \\\n",
    "                                   (msisdn_by_day['count'] > msisdn_sd_above)]['day'])\n",
    "outliers = list(set([x.strftime('%Y-%m-%d') for x in outliers_msisdn + outliers_imei]))\n",
    "pd.DataFrame(outliers, columns=['outliers']).to_csv(toplevel_dir + 'outliers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr = cdr.where(~col('day').isin(outliers))\n",
    "\n",
    "imei_per_msisdn = cdr.groupby('caller_msisdn').agg(countDistinct('imei'))\\\n",
    "    .withColumnRenamed('count(imei)', 'count')\n",
    "save_df(imei_per_msisdn, toplevel_dir + 'imei_per_msisdn.csv')\n",
    "\n",
    "msisdn_per_imei = cdr.groupby('imei').agg(countDistinct('caller_msisdn'))\\\n",
    "    .withColumnRenamed('count(caller_msisdn)', 'count')\n",
    "save_df(msisdn_per_imei, toplevel_dir + 'msisdn_per_imei.csv')\n",
    "\n",
    "count_txns_msisdn = cdr.groupby('caller_msisdn').agg(count('imei'))\\\n",
    "    .withColumnRenamed('count(imei)', 'count')\n",
    "save_df(count_txns_msisdn, toplevel_dir + 'count_transactions_msisdn.csv')\n",
    "\n",
    "count_txns_imei = cdr.groupby('imei').agg(count('caller_msisdn'))\\\n",
    "    .withColumnRenamed('count(caller_msisdn)', 'count')\n",
    "save_df(count_txns_imei, toplevel_dir + 'count_transactions_imei.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Generate datasets of IMEI/MSISD and MSISDN/IMEI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplevel_dir = outdir + 'october'\n",
    "months = ['2020-10']\n",
    "\n",
    "outliers = list(pd.read_csv(toplevel_dir + 'outliers.csv')['outliers'])\n",
    "cols = ['caller_msisdn', 'operator', 'month', 'day', 'imei', 'recipient_msisdn']\n",
    "voice = spark.read.csv(indir + 'voice/2020/11.csv', header=True)\\\n",
    "    .select(cols)\\\n",
    "    .where(col('month').isin(months))\\\n",
    "    .na.drop(subset=['caller_msisdn', 'month', 'day', 'imei'])\\\n",
    "    .where(~(col('day').isin(outliers)))\n",
    "sms = spark.read.csv(indir + 'sms/2020/11.csv', header=True)\\\n",
    "    .select(cols)\\\n",
    "    .where(col('month').isin(months))\\\n",
    "    .na.drop(subset=['caller_msisdn', 'month', 'day', 'imei'])\\\n",
    "    .where(~(col('day').isin(outliers)))\n",
    "cdr = voice.union(sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imei_per_msisdn = cdr.groupby('caller_msisdn').agg(count('imei'))\n",
    "msisdn_per_imei = cdr.groupby('imei').agg(count('caller_msisdn'))\n",
    "save_df(imei_per_msisdn, toplevel_dir + '/imei_per_msisdn.csv')\n",
    "save_df(msisdn_per_imei, toplevel_dir + '/msisdn_per_imei.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define treatment at IMEI level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['caller_msisdn', 'day', 'imei', 'recipient_msisdn', 'interaction']\n",
    "\n",
    "voice_oct = spark.read.csv(indir + 'voice/2020/10.csv', header=True)\\\n",
    "    .select(cols)\\\n",
    "    .na.drop(subset=['caller_msisdn', 'day', 'imei'])\n",
    "sms_oct = spark.read.csv(indir + 'sms/2020/10.csv', header=True)\\\n",
    "    .select(cols)\\\n",
    "    .na.drop(subset=['caller_msisdn', 'day', 'imei'])\n",
    "           \n",
    "voice_nov = spark.read.csv(indir + 'voice/2020/11.csv', header=True)\\\n",
    "    .select(cols)\\\n",
    "    .na.drop(subset=['caller_msisdn', 'day', 'imei'])\n",
    "sms_nov = spark.read.csv(indir + 'sms/2020/11.csv', header=True)\\\n",
    "    .select(cols)\\\n",
    "    .na.drop(subset=['caller_msisdn', 'day', 'imei'])\n",
    "\n",
    "voice_dec = spark.read.csv(indir + 'voice/2020/12.csv', header=True)\\\n",
    "    .select(cols)\\\n",
    "    .na.drop(subset=['caller_msisdn', 'day', 'imei'])\n",
    "sms_dec = spark.read.csv(indir + 'cdr/sms/2020/12.csv', header=True)\\\n",
    "    .select(cols)\\\n",
    "    .na.drop(subset=['caller_msisdn', 'day', 'imei'])\n",
    "\n",
    "voice_jan = spark.read.csv(indir + 'voice/2021/1.csv', header=True)\\\n",
    "    .select(cols)\\\n",
    "    .na.drop(subset=['caller_msisdn', 'day', 'imei'])\n",
    "sms_jan = spark.read.csv(indir + 'sms/2021/1.csv', header=True)\\\n",
    "    .select(cols)\\\n",
    "    .na.drop(subset=['caller_msisdn', 'day', 'imei'])\n",
    "\n",
    "cdr = reduce(DataFrame.unionAll, [voice_nov, sms_nov, voice_dec, sms_dec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novissi = pd.read_csv(admin_fname)\\\n",
    "    [['Gender', 'Age', 'Prefecture', 'Canton', 'RegistrationDate', 'PhoneNumber']]\n",
    "novissi['RegistrationDate'] = pd.to_datetime(novissi['RegistrationDate'])\n",
    "novissi = novissi[novissi['RegistrationDate'] <= pd.to_datetime('2020-12-31')]\n",
    "novissi['rural'] = novissi['Prefecture'].apply(lambda x: 0 if x in ['GOLFE', 'AGOE-NYIVE', 'TCHAOUDJO'] else 1)\n",
    "\n",
    "# Check registered November-December\n",
    "novissi['registered_nov_dec'] = ((novissi['RegistrationDate'] >= pd.to_datetime('2020-11-01')) & \\\n",
    "                                 (novissi['RegistrationDate'] <= pd.to_datetime('2020-12-31')))\\\n",
    "                                .astype('int')\n",
    "novissi['registered_nov'] = ((novissi['RegistrationDate'] >= pd.to_datetime('2020-11-01')) & \\\n",
    "                             (novissi['RegistrationDate'] <= pd.to_datetime('2020-11-30')))\\\n",
    ".astype('int')\n",
    "print('Percent between November and December: %.2f' % (100*(novissi['registered_nov_dec'].mean())))\n",
    "\n",
    "# Check in targeted canton\n",
    "targeted_cantons = pd.read_csv(cantons_assignment_fname)\\\n",
    "    .rename({'novissi_prefecture_name':'Prefecture', 'novissi_canton_name':'Canton', \n",
    "             'targeted':'targeted_canton'}, axis=1)\\\n",
    "    [['targeted_canton', 'Prefecture', 'Canton']]\n",
    "novissi = novissi.merge(targeted_cantons, on=['Prefecture', 'Canton'], how='left')\n",
    "novissi['targeted_canton'] = novissi['targeted_canton'].fillna(0)\n",
    "print('Percent in targeted cantons: %.2f' % (100*(novissi[novissi['registered_nov_dec'] == 1]['targeted_canton']\\\n",
    "                                                  .mean())))\n",
    "\n",
    "# Check below wealth threshold\n",
    "wealth_scores = pd.read_csv(rct_assignment_fname)\\\n",
    "    .rename({'phone_number':'PhoneNumber', 'cdr_pmt':'poverty', 'treatment':'treated'}, axis=1)\\\n",
    "    [['PhoneNumber', 'poverty', 'treated']]\n",
    "novissi = novissi.merge(wealth_scores, on='PhoneNumber', how='left')\n",
    "novissi['below_wealth_threshold'] = (novissi['treated'] >= 0).astype('int')\n",
    "print('Percent below wealth threshold: %.2f' % (100*(novissi[(novissi['registered_nov_dec'] == 1) & \n",
    "                                                             (novissi['targeted_canton'] == 1)]\\\n",
    "                                                     ['below_wealth_threshold'].mean())))\n",
    "print('Percent treated: %.2f' % (100*(novissi[(novissi['registered_nov_dec'] == 1) & \n",
    "                                              (novissi['targeted_canton'] == 1) & \n",
    "                                              (novissi['below_wealth_threshold'] == 1)]\\\n",
    "                                                     ['treated'].mean())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin = spark.createDataFrame(novissi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_time = cdr.withColumn('day', to_timestamp(col('day')))\\\n",
    "    .withColumnRenamed('caller_msisdn', 'PhoneNumber')\\\n",
    "    .join(admin, on=['PhoneNumber'])\\\n",
    "    .withColumn('timedif', abs(datediff(col('day'), col('RegistrationDate'))))\\\n",
    "    .withColumn('min_timedif', min('timedif').over(Window.partitionBy('PhoneNumber')))\\\n",
    "    .where(col('timedif') == col('min_timedif'))\n",
    "\n",
    "max_count = min_time.groupby(['PhoneNumber', 'imei']).agg(count('timedif'), first('timedif'))\\\n",
    "    .withColumnRenamed('count(timedif)', 'count_txns_on_day')\\\n",
    "    .withColumnRenamed('first(timedif)', 'days_to_txn')\\\n",
    "    .withColumn('max_txns', max('count_txns_on_day').over(Window.partitionBy('PhoneNumber')))\\\n",
    "    .where(col('count_txns_on_day') == col('max_txns'))\n",
    "\n",
    "random_choice = max_count.withColumn('rand', rand())\\\n",
    "    .withColumn('max_random', max('rand').over(Window.partitionBy('PhoneNumber')))\\\n",
    "    .where(col('rand') == col('max_random'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_one_min_imei = min_time.groupby('PhoneNumber').agg(countDistinct('imei'))\\\n",
    "    .where(col('count(imei)') > 1)\\\n",
    "    .count()\n",
    "\n",
    "print('Share of phone numbers with more than one IMEI on minimum day: %.2f' % \n",
    "     (100*more_than_one_min_imei/min_time.select('PhoneNumber').distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_one_max_count = max_count.groupby('PhoneNumber').agg(countDistinct('imei'))\\\n",
    "    .where(col('count(imei)') > 1)\\\n",
    "    .count()\n",
    "\n",
    "print('Share of phone numbers with more than one IMEI with the max count on the minimum day: %.2f' % \n",
    "     (100*more_than_one_max_count/max_count.select('PhoneNumber').distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(random_choice, indir + 'imei_assignments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imeis = pd.read_csv(indir + 'imei_assignments.csv')\n",
    "print('Share of transactions within 1 day of registration: %.2f' % \n",
    "     (100*len(imeis[imeis['hours_to_txn'] <= 1])/len(imeis)) + '%')\n",
    "print('Share of transactions within 7 days of registration: %.2f' % \n",
    "     (100*len(imeis[imeis['hours_to_txn'] <= 7])/len(imeis)) + '%')\n",
    "print('Share of transactions within 30 days of registration: %.2f' % \n",
    "     (100*len(imeis[imeis['hours_to_txn'] <= 30])/len(imeis)) + '%')\n",
    "grouped = imeis.groupby('imei').agg('count')\n",
    "print('Share of IMEIs linked to more than one MSISDN: %.2f' % \n",
    "     (100*len(grouped[grouped['PhoneNumber'] > 1])/len(grouped)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('IMEI-centric dataset: %i' % len(imeis))\n",
    "imeis_deduplicate = imeis.drop_duplicates(subset=['imei'])\n",
    "imeis_deduplicate.to_csv(outdir + 'imei_assignments_deduplicated.csv',\n",
    "                        index=False)\n",
    "print('IMEI-centric dataset, deduplicated: %i' % len(imeis_no_duplicates))\n",
    "counts = imeis.groupby('imei', as_index=False).agg('count')[['imei', 'PhoneNumber']]\n",
    "no_duplicates = set(counts[counts['PhoneNumber'] == 1]['imei'])\n",
    "imeis_drop_duplicates = imeis[imeis['imei'].isin(no_duplicates)]\n",
    "imeis_drop_duplicates.to_csv(outdir + 'imei_assignments_drop_duplicates.csv',\n",
    "                        index=False)\n",
    "print('IMEI-centric dataset, no duplicates: %i' % len(imeis_drop_duplicates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Table 2 Panel A: Entire Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplevel_dir = indir + 'january/'\n",
    "\n",
    "imei_per_msisdn = pd.read_csv(toplevel_dir + 'imei_per_msisdn.csv')\n",
    "msisdn_per_imei = pd.read_csv(toplevel_dir + 'msisdn_per_imei.csv')\n",
    "outcomes = [('imei_per_msisdn', imei_per_msisdn), \n",
    "            ('msisdn_per_imei', msisdn_per_imei)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "for label, outcome in outcomes:\n",
    "    column = ['%.2f (%.2f)' % (outcome['count'].mean(), outcome['count'].std()), \n",
    "              '%.2f'% outcome['count'].median(), \n",
    "              '%.2f' % outcome['count'].mode()[0], \n",
    "              '%.2f' % (100*(outcome['count'] > 1).mean()),\n",
    "              '%i' % len(outcome)]\n",
    "    table.append(column)\n",
    "\n",
    "table = pd.DataFrame(table).T\n",
    "table.columns = [label for label, _ in outcomes]\n",
    "table.index = ['Mean', 'Median', 'Mode', 'Share', 'N']\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Match to administrative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "novissi = pd.read_csv(admin_fname)[['Gender', 'Age', 'Prefecture', 'Canton', 'RegistrationDate', 'PhoneNumber']]\n",
    "novissi['RegistrationDate'] = pd.to_datetime(novissi['RegistrationDate'])\n",
    "novissi = novissi[novissi['RegistrationDate'] <= pd.to_datetime('2020-12-31')]\n",
    "novissi['rural'] = novissi['Prefecture'].apply(lambda x: 0 if x in \n",
    "                                               ['LOME COMMUNE', 'GOLFE', 'AGOE-NYIVE', 'TCHAOUDJO'] else 1)\n",
    "\n",
    "# Check registered November-December\n",
    "novissi['registered_nov_dec'] = ((novissi['RegistrationDate'] >= pd.to_datetime('2020-11-01')) & \\\n",
    "                                 (novissi['RegistrationDate'] <= pd.to_datetime('2020-12-31')))\\\n",
    "                                .astype('int')\n",
    "novissi['registered_nov'] = ((novissi['RegistrationDate'] >= pd.to_datetime('2020-11-01')) & \\\n",
    "                             (novissi['RegistrationDate'] <= pd.to_datetime('2020-11-30')))\\\n",
    ".astype('int')\n",
    "print('Percent between November and December: %.2f' % (100*(novissi['registered_nov_dec'].mean())))\n",
    "\n",
    "# Check in targeted canton\n",
    "targeted_cantons = pd.read_csv(canton_assignment_fname)\\\n",
    "    .rename({'novissi_prefecture_name':'Prefecture', 'novissi_canton_name':'Canton', \n",
    "             'targeted':'targeted_canton'}, axis=1)\\\n",
    "    [['targeted_canton', 'Prefecture', 'Canton']]\n",
    "novissi = novissi.merge(targeted_cantons, on=['Prefecture', 'Canton'], how='left')\n",
    "novissi['targeted_canton'] = novissi['targeted_canton'].fillna(0)\n",
    "print('Percent in targeted cantons: %.2f' % (100*(novissi[novissi['registered_nov_dec'] == 1]['targeted_canton']\\\n",
    "                                                  .mean())))\n",
    "\n",
    "# Check below wealth threshold\n",
    "wealth_scores = pd.read_csv(rct_assignment_fname)\\\n",
    "    .rename({'phone_number':'PhoneNumber', 'cdr_pmt':'poverty', 'treatment':'treated'}, axis=1)\\\n",
    "    [['PhoneNumber', 'poverty', 'treated']]\n",
    "novissi = novissi.merge(wealth_scores, on='PhoneNumber', how='left')\n",
    "novissi['below_wealth_threshold'] = (novissi['treated'] >= 0).astype('int')\n",
    "print('Percent below wealth threshold: %.2f' % (100*(novissi[(novissi['registered_nov_dec'] == 1) & \n",
    "                                                             (novissi['targeted_canton'] == 1)]\\\n",
    "                                                     ['below_wealth_threshold'].mean())))\n",
    "print('Percent treated: %.2f' % (100*(novissi[(novissi['registered_nov_dec'] == 1) & \n",
    "                                              (novissi['targeted_canton'] == 1) & \n",
    "                                              (novissi['below_wealth_threshold'] == 1)]\\\n",
    "                                                     ['treated'].mean())))\n",
    "\n",
    "# Link to IMEI\n",
    "imeis = pd.read_csv(indir + 'scratch/imei_assignments_deduplicated.csv')\\\n",
    "    [['PhoneNumber', 'imei']]\n",
    "novissi = novissi.merge(imeis, on='PhoneNumber', how='left')\n",
    "print('Percent of records linked to IMEI: %.2f' % (100 - 100*novissi['imei'].isnull().mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1 Panel A and Table 2 Panel B: Matched to Admin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = novissi[novissi['registered_nov_dec'] == 1].copy()\n",
    "print(df.shape)\n",
    "\n",
    "imei_per_msisdn = pd.read_csv(toplevel_dir + 'imei_per_msisdn.csv')\\\n",
    "    .rename({'caller_msisdn':'PhoneNumber', 'count':'imei_per_msisdn'}, axis=1)\n",
    "msisdn_per_imei = pd.read_csv(toplevel_dir + 'msisdn_per_imei.csv')\\\n",
    "    .rename({'count':'msisdn_per_imei'}, axis=1)\n",
    "counts_msisdn = pd.read_csv(toplevel_dir + 'count_transactions_msisdn.csv')\\\n",
    "    .rename({'caller_msisdn':'PhoneNumber', 'count':'msisdn_count_txns'}, axis=1)\n",
    "counts_imei = pd.read_csv(toplevel_dir + 'count_transactions_imei.csv')\\\n",
    "    .rename({ 'count':'imei_count_txns'}, axis=1)\n",
    "\n",
    "msisdn_data = imei_per_msisdn.drop_duplicates(subset=['PhoneNumber'])\\\n",
    "    .merge(counts_msisdn.drop_duplicates(subset=['PhoneNumber']), on='PhoneNumber', how='left')\n",
    "imei_data = msisdn_per_imei.drop_duplicates(subset=['imei'])\\\n",
    "    .merge(counts_imei.drop_duplicates(subset=['imei']), on='imei', how='left')\n",
    "           \n",
    "df = df.merge(msisdn_data, on='PhoneNumber', how='left')\\\n",
    "    .merge(imei_data, on='imei', how='left')\n",
    "\n",
    "print(df.shape)\n",
    "print('Percent with MSISDN data: %.2f' % (100 - 100*df['imei_per_msisdn'].isnull().mean()))\n",
    "print('Percent with IMEI data: %.2f' % (100 - 100*df['msisdn_per_imei'].isnull().mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "for outcome in ['imei_per_msisdn', 'msisdn_per_imei']:\n",
    "    df_outcome = df.dropna(subset=[outcome])\n",
    "    column = ['%.2f (%.2f)' % (df_outcome[outcome].mean(), df_outcome[outcome].std()), \n",
    "              '%.2f'% df_outcome[outcome].median(), \n",
    "              '%.2f' % df_outcome[outcome].mode()[0], \n",
    "              '%.2f' % (100*(df_outcome[outcome] > 1).mean()),\n",
    "              '%i' % len(df_outcome)]\n",
    "    table.append(column)\n",
    "\n",
    "table = pd.DataFrame(table).T\n",
    "table.columns = ['IMEI per MSISDN', 'MSISDN per IMEI']\n",
    "table.index = ['Mean', 'Median', 'Mode', 'Share', 'N']\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "df_outcome = df.copy()\n",
    "\n",
    "df_outcome['Age: 18-30'] = df_outcome['Age'].apply(lambda x: x <= 30).astype('int')\n",
    "df_outcome['Age: 30-40'] = df_outcome['Age'].apply(lambda x: x > 30 and x <= 40).astype('int')\n",
    "df_outcome['Age: 40-50'] = df_outcome['Age'].apply(lambda x: x > 40 and x <=50).astype('int')\n",
    "df_outcome['Age: 50+'] = df_outcome['Age'].apply(lambda x: x > 50).astype('int')\n",
    "\n",
    "column = ['%i' % (len(df_outcome[df_outcome['Gender'] == 'F'])), \n",
    "          '%i' % (len(df_outcome[df_outcome['Gender'] == 'M'])),\n",
    "         '%i' % (len(df_outcome[df_outcome['Age: 18-30'] == 1])),\n",
    "         '%i' % (len(df_outcome[df_outcome['Age: 30-40'] == 1])),\n",
    "         '%i' % (len(df_outcome[df_outcome['Age: 40-50'] == 1])),\n",
    "         '%i' % (len(df_outcome[df_outcome['Age: 50+'] == 1])),\n",
    "         '%i' % (len(df_outcome[df_outcome['rural'] == 1])),\n",
    "         '%i' % (len(df_outcome[df_outcome['rural'] == 0]))]\n",
    "table.append(column)\n",
    "\n",
    "column = ['%.2f' % (100*len(df_outcome[df_outcome['Gender'] == 'F'])/len(df_outcome)) + '%', \n",
    "          '%.2f' % (100*len(df_outcome[df_outcome['Gender'] == 'M'])/len(df_outcome)) + '%',\n",
    "         '%.2f' % (100*len(df_outcome[df_outcome['Age: 18-30'] == 1])/len(df_outcome)) + '%',\n",
    "         '%.2f' % (100*len(df_outcome[df_outcome['Age: 30-40'] == 1])/len(df_outcome)) + '%',\n",
    "         '%.2f' % (100*len(df_outcome[df_outcome['Age: 40-50'] == 1])/len(df_outcome)) + '%',\n",
    "         '%.2f' % (100*len(df_outcome[df_outcome['Age: 50+'] == 1])/len(df_outcome)) + '%',\n",
    "         '%.2f' % (100*len(df_outcome[df_outcome['rural'] == 1])/len(df_outcome)) + '%',\n",
    "         '%.2f' % (100*len(df_outcome[df_outcome['rural'] == 0])/len(df_outcome)) + '%']\n",
    "table.append(column)\n",
    "\n",
    "table = pd.DataFrame(table).T\n",
    "table.columns = ['N', '%']\n",
    "table.index = ['Female', 'Male', '18-30', '30-40', '40-50', '50+', 'Rural', 'Urban']\n",
    "print('N=%i' % len(df_outcome))\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1 Panel B and Table 2 Panel C: Enrolled in RCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "df_rct = df[(df['registered_nov_dec'] == 1) & (df['targeted_canton'] == 1) & \n",
    "            (df['below_wealth_threshold'] == 1)].copy()\n",
    "for outcome in ['imei_per_msisdn', 'msisdn_per_imei']:\n",
    "    df_outcome = df_rct.dropna(subset=[outcome])\n",
    "    column = ['%.2f (%.2f)' % (df_outcome[outcome].mean(), df_outcome[outcome].std()), \n",
    "              '%.2f'% df_outcome[outcome].median(), \n",
    "              '%.2f' % df_outcome[outcome].mode()[0], \n",
    "              '%.2f' % (100*(df_outcome[outcome] > 1).mean()),\n",
    "              '%i' % len(df_outcome)]\n",
    "    table.append(column)\n",
    "\n",
    "table = pd.DataFrame(table).T\n",
    "table.columns = ['IMEI per MSISDN', 'MSISDN per IMEI']\n",
    "table.index = ['Mean', 'Median', 'Mode', 'Share', 'N']\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "\n",
    "df_outcome = df_rct.copy()\n",
    "\n",
    "df_outcome['Age: 18-30'] = df_outcome['Age'].apply(lambda x: x <= 30).astype('int')\n",
    "df_outcome['Age: 30-40'] = df_outcome['Age'].apply(lambda x: x > 30 and x <= 40).astype('int')\n",
    "df_outcome['Age: 40-50'] = df_outcome['Age'].apply(lambda x: x > 40 and x <=50).astype('int')\n",
    "df_outcome['Age: 50+'] = df_outcome['Age'].apply(lambda x: x > 50).astype('int')\n",
    "\n",
    "column = ['%i' % (len(df_outcome[df_outcome['Gender'] == 'F'])), \n",
    "          '%i' % (len(df_outcome[df_outcome['Gender'] == 'M'])),\n",
    "         '%i' % (len(df_outcome[df_outcome['Age: 18-30'] == 1])),\n",
    "         '%i' % (len(df_outcome[df_outcome['Age: 30-40'] == 1])),\n",
    "         '%i' % (len(df_outcome[df_outcome['Age: 40-50'] == 1])),\n",
    "         '%i' % (len(df_outcome[df_outcome['Age: 50+'] == 1])),\n",
    "         '%i' % (len(df_outcome[df_outcome['rural'] == 1])),\n",
    "         '%i' % (len(df_outcome[df_outcome['rural'] == 0]))]\n",
    "table.append(column)\n",
    "\n",
    "column = ['%.2f' % (100*len(df_outcome[df_outcome['Gender'] == 'F'])/len(df_outcome)) + '%', \n",
    "          '%.2f' % (100*len(df_outcome[df_outcome['Gender'] == 'M'])/len(df_outcome)) + '%',\n",
    "         '%.2f' % (100*len(df_outcome[df_outcome['Age: 18-30'] == 1])/len(df_outcome)) + '%',\n",
    "         '%.2f' % (100*len(df_outcome[df_outcome['Age: 30-40'] == 1])/len(df_outcome)) + '%',\n",
    "         '%.2f' % (100*len(df_outcome[df_outcome['Age: 40-50'] == 1])/len(df_outcome)) + '%',\n",
    "         '%.2f' % (100*len(df_outcome[df_outcome['Age: 50+'] == 1])/len(df_outcome)) + '%',\n",
    "         '%.2f' % (100*len(df_outcome[df_outcome['rural'] == 1])/len(df_outcome)) + '%',\n",
    "         '%.2f' % (100*len(df_outcome[df_outcome['rural'] == 0])/len(df_outcome)) + '%']\n",
    "table.append(column)\n",
    "table = pd.DataFrame(table).T\n",
    "table.columns = ['N', '%']\n",
    "table.index = ['Female', 'Male', '18-30', '30-40', '40-50', '50+', 'Rural', 'Urban']\n",
    "print(len(df_outcome))\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix Table: Baseline Tests for Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []\n",
    "df_balance = df_rct.copy()\n",
    "df_balance['female'] = df_balance['Gender'].apply(lambda x: 1 if x == 'F' else 0)\n",
    "df_balance['shared_msisdn'] = df_balance['imei_per_msisdn']\\\n",
    "    .apply(lambda x: 1 if x > 1 else 0 if x == 1 else np.nan)\n",
    "df_balance['shared_imei'] = df_balance['msisdn_per_imei']\\\n",
    "    .apply(lambda x: 1 if x > 1 else 0 if x == 1 else np.nan)\n",
    "\n",
    "treatment = df_balance[df_balance['treated'] == 1]\n",
    "control = df_balance[df_balance['treated'] == 0]\n",
    "\n",
    "for var in ['female', 'Age', 'shared_msisdn', 'shared_imei', 'msisdn_count_txns']:\n",
    "    ttest = ttest_ind(treatment[var].dropna(), control[var].dropna()).pvalue \n",
    "    stars = '***' if ttest < 0.001 else '**' if ttest < 0.01 else '*' if ttest < 0.05 else ''\n",
    "    row = ['%.2f (%.2f)' % (treatment[var].mean(), treatment[var].std()), \n",
    "          '%.2f (%.2f)' % (control[var].mean(), control[var].std()),\n",
    "          '%.2f' % (treatment[var].mean() - control[var].mean()) + stars]\n",
    "    table.append(row)\n",
    "    \n",
    "table.append([len(treatment), len(control), len(df_balance)])\n",
    "table = pd.DataFrame(table)\n",
    "table.columns = ['Treatment', 'Control', 'Difference']\n",
    "table.index = ['% Women', 'Age', 'Shared SIM', 'Shared Device', 'Number of Transactions', 'N']\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1: Geographic Heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "\n",
    "data['imei_per_msisdn'] = 100*(data['imei_per_msisdn'] > 1).astype('int')\n",
    "data['msisdn_per_imei'] = 100*(data['msisdn_per_imei'] > 1).astype('int')\n",
    "\n",
    "pop = data.groupby('Prefecture', as_index=False).agg('count')[['Prefecture', 'Gender']]\\\n",
    "    .rename({'Gender':'count'}, axis=1)\n",
    "pop = pop[pop['count'] > 10]\n",
    "avg = data.groupby('Prefecture', as_index=False).agg('mean')\n",
    "avg = pop.merge(avg, on='Prefecture')\n",
    "shapefile = gpd.read_file(shapefile_fname)[['PREFECTURE', 'geometry']]\\\n",
    "    .rename({'PREFECTURE':'Prefecture'}, axis=1)\n",
    "shapefile['Prefecture'] = shapefile['Prefecture']\\\n",
    "    .apply(lambda x: 'KPENDJAL OUEST' if x == 'KPENDJAL-OUEST' else \n",
    "          'GOLFE' if x == 'LOME COMMUNE' else\n",
    "          'OTI SUD' if x == 'OTI-SUD' else\n",
    "          'MO' if x == 'PLAINE DU MO' else x)\n",
    "avg = shapefile.merge(avg, on='Prefecture', how='inner')\n",
    "\n",
    "sns.reset_orig()\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "fmt = lambda x, pos: '{:.1%}'.format(x)\n",
    "#cbar = plt.colorbar(format=FuncFormatter(fmt))\n",
    "avg.plot(ax=ax[0], column=['imei_per_msisdn'], legend=True, \n",
    "         legend_kwds={'label': 'Percent Shared', 'shrink':0.5}, edgecolor='darkgrey', linewidth=0.5)\n",
    "\n",
    "shapefile.plot(ax=ax[1], color='lightgrey')\n",
    "avg.plot(ax=ax[1], column=['msisdn_per_imei'], legend=True,\n",
    "        legend_kwds={'label': 'Percent Shared', 'shrink':0.5}, edgecolor='darkgrey', linewidth=0.5)\n",
    "\n",
    "cities = pd.DataFrame([[6.19, 1.2254], [8.9228, 1.1353]])\n",
    "cities.columns = ['longitude', 'latitude']\n",
    "cities = gpd.GeoDataFrame(cities, geometry=gpd.points_from_xy(cities['latitude'], cities['longitude']))\n",
    "cities.plot(ax=ax[0], color='darkred', markersize=200, linewidth=0.5, edgecolor='black')\n",
    "cities.plot(ax=ax[1], color='darkred', markersize=200, linewidth=0.5, edgecolor='black')\n",
    "\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "ax[0].set_title('Shared MSISDNs', fontsize='xx-large')\n",
    "ax[1].set_title('Shared IMEIs', fontsize='xx-large')\n",
    "\n",
    "ax[0].annotate('Lomé', xy=[.27, .105], xytext=[.47, .15], xycoords='figure fraction', \n",
    "               textcoords='figure fraction', arrowprops={'arrowstyle':'->'}, fontsize='x-large')\n",
    "ax[1].annotate('Lomé', xy=[.75, .105], xytext=[.47, .15], xycoords='figure fraction', \n",
    "               textcoords='figure fraction', arrowprops={'arrowstyle':'->'}, fontsize='x-large')\n",
    "ax[0].annotate('Tchaoudjo', xy=[.25, .555], xytext=[.35, .82], xycoords='figure fraction', \n",
    "               textcoords='figure fraction', arrowprops={'arrowstyle':'->'}, fontsize='x-large')\n",
    "ax[1].annotate('Tchaoudjo', xy=[.74, .555], xytext=[.35, .82], xycoords='figure fraction', \n",
    "               textcoords='figure fraction', arrowprops={'arrowstyle':'->'}, fontsize='x-large')\n",
    "plt.savefig(outdir + 'maps.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 3: Heterogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "data = data[data['registered_nov_dec'] == 1]\n",
    "data['Gender'] = data['Gender'].apply(lambda x: 1 if x == 'F' else 0)\n",
    "data['Age: 18-30'] = data['Age'].apply(lambda x: x <= 30).astype('int')\n",
    "data['Age: 30-40'] = data['Age'].apply(lambda x: x > 30 and x <= 40).astype('int')\n",
    "data['Age: 40-50'] = data['Age'].apply(lambda x: x > 40 and x <=50).astype('int')\n",
    "data['Age: 50+'] = data['Age'].apply(lambda x: x > 50).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'imei_per_msisdn'\n",
    "regressions = [\n",
    "    ('Gender', ['Gender']),\n",
    "    ('Gender', ['msisdn_count_txns', 'Gender']),\n",
    "    ('Age', ['Age: 30-40', 'Age: 40-50', 'Age: 50+']),\n",
    "    ('Age', ['msisdn_count_txns', 'Age: 30-40', 'Age: 40-50', 'Age: 50+']),\n",
    "    ('Geography', ['rural']),\n",
    "    ('Geography', ['msisdn_count_txns', 'rural']),\n",
    "    ('Joint', ['msisdn_count_txns', 'Gender', 'Age: 30-40', 'Age: 40-50', 'Age: 50+', 'rural'])\n",
    "]\n",
    "\n",
    "table = []\n",
    "for label, covariates in regressions:\n",
    "    regression_data = data[covariates + [outcome]].dropna().copy()\n",
    "    regression_data[outcome] = (regression_data[outcome] > 1).astype('int')\n",
    "\n",
    "    y = regression_data[outcome]\n",
    "    x = sm.add_constant(regression_data[covariates].copy())\n",
    "    result = sm.OLS(y, x).fit()\n",
    "    \n",
    "    stars = {result.pvalues.index[i]:'***' if result.pvalues[i] < 0.001 else '**' if result.pvalues[i] < 0.01 \\\n",
    "            else '*' if result.pvalues[i] < 0.05 else '' for i in range(len(result.pvalues))}\n",
    "    params = {result.params.index[i]: ('%.4f' % result.params[i]) + stars[result.params.index[i]] \\\n",
    "              for i in range(len(result.params))}\n",
    "    table.append({**params, **{'rsquared': '%.4f' % result.rsquared, 'n':'%i' % result.nobs}})\n",
    "\n",
    "table = pd.DataFrame(table).T.sort_index().fillna('')\n",
    "table.columns = [label for label, _ in regressions]\n",
    "table = table.reindex(index=['const', 'msisdn_count_txns', 'Gender', 'Age: 30-40', 'Age: 40-50',\n",
    "                             'Age: 50+', 'rural', 'rsquared', 'n'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'msisdn_per_imei'\n",
    "regressions = [\n",
    "    ('Gender', ['Gender']),\n",
    "    ('Gender', ['imei_count_txns', 'Gender']),\n",
    "    ('Age', ['Age: 30-40', 'Age: 40-50', 'Age: 50+']),\n",
    "    ('Age', ['imei_count_txns', 'Age: 30-40', 'Age: 40-50', 'Age: 50+']),\n",
    "    ('Geography', ['rural']),\n",
    "    ('Geography', ['imei_count_txns', 'rural']),\n",
    "    ('Joint', ['imei_count_txns', 'Gender', 'Age: 30-40', 'Age: 40-50', 'Age: 50+', 'rural'])\n",
    "]\n",
    "\n",
    "table = []\n",
    "for label, covariates in regressions:\n",
    "    regression_data = data[covariates + [outcome]].dropna().copy()\n",
    "    regression_data[outcome] = (regression_data[outcome] > 1).astype('int')\n",
    "\n",
    "    y = regression_data[outcome]\n",
    "    x = sm.add_constant(regression_data[covariates].copy())\n",
    "    result = sm.OLS(y, x).fit()\n",
    "    \n",
    "    stars = {result.pvalues.index[i]:'***' if result.pvalues[i] < 0.001 else '**' if result.pvalues[i] < 0.01 \\\n",
    "            else '*' if result.pvalues[i] < 0.05 else '' for i in range(len(result.pvalues))}\n",
    "    params = {result.params.index[i]: ('%.4f' % result.params[i]) + stars[result.params.index[i]] \\\n",
    "              for i in range(len(result.params))}\n",
    "    table.append({**params, **{'rsquared': '%.4f' % result.rsquared, 'n':'%i' % result.nobs}})\n",
    "\n",
    "table = pd.DataFrame(table).T.sort_index().fillna('')\n",
    "table.columns = [label for label, _ in regressions]\n",
    "table = table.reindex(index=['const', 'imei_count_txns', 'Gender', 'Age: 30-40', 'Age: 40-50',\n",
    "                             'Age: 50+', 'rural', 'rsquared', 'n'])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 4: Impact Evaluation and Table 6: Heterogeneous Treatment Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "data = data[data['registered_nov_dec'] == 1]\n",
    "data = data[data['targeted_canton'] == 1]\n",
    "data = data[data['below_wealth_threshold'] == 1]\n",
    "data['Gender'] = data['Gender'].apply(lambda x: 1 if x == 'F' else 0)\n",
    "data['Age: 18-30'] = data['Age'].apply(lambda x: x <= 30).astype('int')\n",
    "data['Age: 30-40'] = data['Age'].apply(lambda x: x > 30 and x <= 40).astype('int')\n",
    "data['Age: 40-50'] = data['Age'].apply(lambda x: x > 40 and x <=50).astype('int')\n",
    "data['Age: 50+'] = data['Age'].apply(lambda x: x > 50).astype('int')\n",
    "data['Treatment x Female'] = data['Gender']*data['treated']\n",
    "data['Treatment x Age: 50+'] = data['Age: 50+']*data['treated']\n",
    "data['Treatment x Age: 30-40'] = data['Age: 30-40']*data['treated']\n",
    "data['Treatment x Age: 40-50'] = data['Age: 40-50']*data['treated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'imei_per_msisdn'\n",
    "regressions = [\n",
    "    ('Basic', ['treated']),\n",
    "    ('Transactions Control', ['treated', 'msisdn_count_txns']),\n",
    "    ('Demographic controls', ['treated', 'msisdn_count_txns', 'Gender', 'Age: 30-40', 'Age: 40-50', 'Age: 50+']),\n",
    "    ('Gender Heterogeneous Effects', ['treated', 'msisdn_count_txns', 'Gender', 'Treatment x Female']),\n",
    "    ('Age Heterogeneous Effects', ['treated', 'msisdn_count_txns', 'Age: 30-40', 'Age: 40-50', 'Age: 50+',\n",
    "                                  'Treatment x Age: 30-40', 'Treatment x Age: 40-50', 'Treatment x Age: 50+'])\n",
    "]\n",
    "\n",
    "table = []\n",
    "for label, covariates in regressions:\n",
    "    regression_data = data[covariates + [outcome]].dropna().copy()\n",
    "    regression_data[outcome] = (regression_data[outcome] > 1).astype('int')\n",
    "\n",
    "    y = regression_data[outcome]\n",
    "    x = sm.add_constant(regression_data[covariates].copy())\n",
    "    result = sm.OLS(y, x).fit()\n",
    "    \n",
    "    stars = {result.pvalues.index[i]:'***' if result.pvalues[i] < 0.001 else '**' if result.pvalues[i] < 0.01 \\\n",
    "            else '*' if result.pvalues[i] < 0.05 else '' for i in range(len(result.pvalues))}\n",
    "    params = {result.params.index[i]: ('%.4f' % result.params[i]) + stars[result.params.index[i]] \\\n",
    "              for i in range(len(result.params))}\n",
    "    table.append({**params, **{'rsquared': '%.4f' % result.rsquared, 'n':'%i' % result.nobs}})\n",
    "\n",
    "table = pd.DataFrame(table).T.sort_index().fillna('')\n",
    "table.columns = [label for label, _ in regressions]\n",
    "table = table.reindex(['const', 'treated', 'msisdn_count_txns', 'Gender', 'Age: 30-40', 'Age: 40-50', \n",
    "                       'Age: 50+', 'Treatment x Female', 'Treatment x Age: 30-40', 'Treatment x Age: 40-50', \n",
    "                       'Treatment x Age: 50+', 'rsquared', 'n'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outcome = 'msisdn_per_imei'\n",
    "regressions = [\n",
    "    ('Basic', ['treated']),\n",
    "    ('Transactions Control', ['treated', 'imei_count_txns']),\n",
    "    ('Demographic controls', ['treated', 'imei_count_txns', 'Gender', 'Age: 30-40', 'Age: 40-50', 'Age: 50+']),\n",
    "    ('Gender Heterogeneous Effects', ['treated', 'imei_count_txns', 'Gender', 'Treatment x Female']),\n",
    "    ('Age Heterogeneous Effects', ['treated', 'imei_count_txns', 'Age: 30-40', 'Age: 40-50', 'Age: 50+',\n",
    "                                  'Treatment x Age: 30-40', 'Treatment x Age: 40-50', 'Treatment x Age: 50+'])\n",
    "]\n",
    "\n",
    "table = []\n",
    "for label, covariates in regressions:\n",
    "    regression_data = data[covariates + [outcome]].dropna().copy()\n",
    "    regression_data[outcome] = (regression_data[outcome] > 1).astype('int')\n",
    "\n",
    "    y = regression_data[outcome]\n",
    "    x = sm.add_constant(regression_data[covariates].copy())\n",
    "    result = sm.OLS(y, x).fit()\n",
    "    \n",
    "    stars = {result.pvalues.index[i]:'***' if result.pvalues[i] < 0.001 else '**' if result.pvalues[i] < 0.01 \\\n",
    "            else '*' if result.pvalues[i] < 0.05 else '' for i in range(len(result.pvalues))}\n",
    "    params = {result.params.index[i]: ('%.4f' % result.params[i]) + stars[result.params.index[i]] \\\n",
    "              for i in range(len(result.params))}\n",
    "    table.append({**params, **{'rsquared': '%.4f' % result.rsquared, 'n':'%i' % result.nobs}})\n",
    "\n",
    "table = pd.DataFrame(table).T.sort_index().fillna('')\n",
    "table.columns = [label for label, _ in regressions]\n",
    "table = table.reindex(['const', 'treated', 'imei_count_txns', 'Gender', 'Age: 30-40', 'Age: 40-50', \n",
    "                       'Age: 50+', 'Treatment x Female', 'Treatment x Age: 30-40', 'Treatment x Age: 40-50', \n",
    "                       'Treatment x Age: 50+', 'rsquared', 'n'])\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 5: Diff-in-diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = novissi.copy()\n",
    "\n",
    "for month in ['october', 'november', 'december', 'january']:\n",
    "    toplevel_dir = indir + month + '/'\n",
    "\n",
    "    imei_per_msisdn = pd.read_csv(toplevel_dir + 'imei_per_msisdn.csv')\\\n",
    "        .rename({'caller_msisdn':'PhoneNumber', 'count':'imei_per_msisdn_' + month}, axis=1)\\\n",
    "        .drop_duplicates(subset=['PhoneNumber'])\n",
    "    msisdn_per_imei = pd.read_csv(toplevel_dir + 'msisdn_per_imei.csv')\\\n",
    "        .rename({'count':'msisdn_per_imei_' + month}, axis=1)\\\n",
    "        .drop_duplicates(subset=['imei'])\n",
    "    counts_msisdn = pd.read_csv(toplevel_dir + 'count_transactions_msisdn.csv')\\\n",
    "        .rename({'caller_msisdn':'PhoneNumber', 'count':'msisdn_count_txns_' + month}, axis=1)\\\n",
    "        .drop_duplicates(subset=['PhoneNumber'])\n",
    "    counts_imei = pd.read_csv(toplevel_dir + 'count_transactions_imei.csv')\\\n",
    "        .rename({'count':'imei_count_txns_' + month}, axis=1)\\\n",
    "        .drop_duplicates(subset=['imei'])\n",
    "    \n",
    "    df = df.merge(imei_per_msisdn, on='PhoneNumber', how='left')\n",
    "    df = df.merge(msisdn_per_imei, on='imei', how='left')\n",
    "    df = df.merge(counts_msisdn, on='PhoneNumber', how='left')\n",
    "    df = df.merge(counts_imei, on='imei', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "data = data[data['registered_nov_dec'] == 1]\n",
    "data = data[data['targeted_canton'] == 1]\n",
    "data = data[data['below_wealth_threshold'] == 1]\n",
    "\n",
    "data = data[['PhoneNumber', 'imei', 'treated', 'registered_nov'] + \\\n",
    "            [col for col in df.columns if 'count' in col or 'imei_per_msisdn' in col or 'msisdn_per_imei' in col]]\n",
    "\n",
    "columns = ['PhoneNumber', 'imei', 'treated', 'imei_per_msisdn', 'msisdn_per_imei', 'msisdn_count_txns', \n",
    "          'imei_count_txns', 'month', 'treatmentxmonth']\n",
    "october = data[['PhoneNumber', 'imei', 'treated', 'registered_nov'] + \\\n",
    "               [col for col in data.columns if 'october' in col]].copy()\n",
    "october['month'] = 10\n",
    "october['treatmentxmonth'] = 0\n",
    "october = october.drop('registered_nov', axis=1)\n",
    "october.columns = columns\n",
    "\n",
    "november = data[['PhoneNumber', 'imei', 'treated', 'registered_nov'] + \\\n",
    "                [col for col in data.columns if 'november' in col]].copy()\n",
    "november['month'] = 11\n",
    "november['treatmentxmonth'] = november['registered_nov']*november['treated']\n",
    "november = november.drop('registered_nov', axis=1)\n",
    "november.columns = columns\n",
    "\n",
    "december = data[['PhoneNumber', 'imei', 'treated', 'registered_nov'] + \\\n",
    "                [col for col in data.columns if 'december' in col]].copy()\n",
    "december['month'] = 12\n",
    "december['treatmentxmonth'] = december['treated']\n",
    "december = december.drop('registered_nov', axis=1)\n",
    "december.columns = columns\n",
    "\n",
    "january = data[['PhoneNumber', 'imei', 'treated', 'registered_nov'] + \\\n",
    "               [col for col in data.columns if 'january' in col]].copy()\n",
    "january['month'] = 1\n",
    "january['treatmentxmonth'] = january['treated']\n",
    "january = january.drop('registered_nov', axis=1)\n",
    "january.columns = columns\n",
    "\n",
    "data = pd.concat([october, november, december, january])\n",
    "data['month_dummy'] = data['month']\n",
    "data = data.set_index(['PhoneNumber', 'month'])\n",
    "data = pd.get_dummies(data, columns=['month_dummy'], drop_first=False)\n",
    "data = data.drop('month_dummy_10', axis=1)\n",
    "\n",
    "data['msisdn_per_imei'] = data['msisdn_per_imei'].apply(lambda x: np.nan if pd.isnull(x) else 1 if x > 1 else 0)\n",
    "data['imei_per_msisdn'] = data['imei_per_msisdn'].apply(lambda x: np.nan if pd.isnull(x) else 1 if x > 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "timeseries = data.copy()\n",
    "timeseries['month_int'] = [x[1] for x in timeseries.index]\n",
    "timeseries['month_date'] = timeseries['month_int'].apply(lambda x: '2020-10' if x == 10\n",
    "                                                        else '2020-11' if x == 11\n",
    "                                                        else '2020-12' if x == 12\n",
    "                                                        else '2021-01')\n",
    "timeseries['month_date'] = pd.to_datetime(timeseries['month_date'])\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(10, 6))\n",
    "\n",
    "msisdn_timeseries = timeseries[['month_date', 'imei_per_msisdn', 'treated']].dropna().copy()\n",
    "avg = msisdn_timeseries.groupby(['month_date', 'treated'], as_index=False).agg('mean')\n",
    "count = msisdn_timeseries.groupby(['month_date', 'treated'], as_index=False).agg('count')\n",
    "treated = avg[avg['treated'] == 1]\n",
    "untreated = avg[avg['treated'] == 0]\n",
    "ax.plot(treated['month_date'], 100*treated['imei_per_msisdn'], label='Shared MSISDNs', \n",
    "       color='indianred')\n",
    "ax.scatter(treated['month_date'], 100*treated['imei_per_msisdn'], color='indianred')\n",
    "ax.plot(untreated['month_date'], 100*untreated['imei_per_msisdn'], \n",
    "        color='indianred', dashes=[2, 2])\n",
    "ax.scatter(untreated['month_date'], 100*untreated['imei_per_msisdn'], color='indianred')\n",
    "\n",
    "imei_timeseries = timeseries[['month_date', 'msisdn_per_imei', 'treated', 'imei']].dropna().copy()\n",
    "avg = imei_timeseries.groupby(['month_date', 'treated'], as_index=False).agg('mean')\n",
    "count = msisdn_timeseries.groupby(['month_date', 'treated'], as_index=False).agg('count')\n",
    "treated = avg[avg['treated'] == 1]\n",
    "untreated = avg[avg['treated'] == 0]\n",
    "ax.plot(treated['month_date'], 100*treated['msisdn_per_imei'], \n",
    "        label='Shared IMEIs', color='mediumseagreen')\n",
    "ax.scatter(treated['month_date'], 100*treated['msisdn_per_imei'], color='mediumseagreen')\n",
    "ax.plot(untreated['month_date'], 100*untreated['msisdn_per_imei'], color='mediumseagreen', dashes=[2, 2])\n",
    "ax.scatter(untreated['month_date'], 100*untreated['msisdn_per_imei'], color='mediumseagreen')\n",
    "\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%Y'))\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "\n",
    "ax.set_title('Phone Sharing Over Time')\n",
    "ax.legend(loc='best')\n",
    "simpleaxis(ax)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/em/phoneshare.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'imei_per_msisdn'\n",
    "regressions = [\n",
    "    ('Basic', ['treatmentxmonth', 'month_dummy_11', 'month_dummy_12', 'month_dummy_1']),\n",
    "    ('Transactions Control', ['treatmentxmonth', 'msisdn_count_txns', 'month_dummy_11', 'month_dummy_12', \n",
    "                              'month_dummy_1']),\n",
    "]\n",
    "\n",
    "table = []\n",
    "for regression, exog_vars in regressions:\n",
    "    exog = sm.add_constant(data[exog_vars])\n",
    "    mod = PanelOLS(data[outcome], exog, entity_effects=True, time_effects=False)\n",
    "    result = mod.fit(cov_type='clustered', cluster_entity=True)\n",
    "    \n",
    "    stars = {result.pvalues.index[i]:'***' if result.pvalues[i] < 0.001 else '**' if result.pvalues[i] < 0.01 \\\n",
    "            else '*' if result.pvalues[i] < 0.05 else '' for i in range(len(result.pvalues))}\n",
    "    params = {result.params.index[i]: ('%.4f' % result.params[i]) + stars[result.params.index[i]] \\\n",
    "              for i in range(len(result.params))}\n",
    "    table.append({**params, **{'rsquared': '%.4f' % result.rsquared, 'n':'%i' % result.nobs}})\n",
    "    \n",
    "    \n",
    "table = pd.DataFrame(table).T.sort_index().fillna('')\n",
    "table.columns = [label for label, _ in regressions]\n",
    "table = table.reindex(['const', 'treatmentxmonth', 'msisdn_count_txns', 'month_dummy_11', 'month_dummy_12', \n",
    "                       'month_dummy_1', 'rsquared', 'n'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'msisdn_per_imei'\n",
    "regressions = [\n",
    "    ('Basic', ['treatmentxmonth', 'month_dummy_11', 'month_dummy_12', 'month_dummy_1']),\n",
    "    ('Transactions Control', ['treatmentxmonth', 'imei_count_txns', 'month_dummy_11', 'month_dummy_12', \n",
    "                              'month_dummy_1']),\n",
    "]\n",
    "\n",
    "table = []\n",
    "for regression, exog_vars in regressions:\n",
    "    exog = sm.add_constant(data[exog_vars])\n",
    "    mod = PanelOLS(data[outcome], exog, entity_effects=True, time_effects=False)\n",
    "    result = mod.fit(cov_type='clustered', cluster_entity=True)\n",
    "    \n",
    "    stars = {result.pvalues.index[i]:'***' if result.pvalues[i] < 0.001 else '**' if result.pvalues[i] < 0.01 \\\n",
    "            else '*' if result.pvalues[i] < 0.05 else '' for i in range(len(result.pvalues))}\n",
    "    params = {result.params.index[i]: ('%.4f' % result.params[i]) + stars[result.params.index[i]] \\\n",
    "              for i in range(len(result.params))}\n",
    "    table.append({**params, **{'rsquared': '%.4f' % result.rsquared, 'n':'%i' % result.nobs}})\n",
    "    \n",
    "    \n",
    "table = pd.DataFrame(table).T.sort_index().fillna('')\n",
    "table.columns = [label for label, _ in regressions]\n",
    "table = table.reindex(['const', 'treatmentxmonth', 'imei_count_txns', 'month_dummy_11', 'month_dummy_12', \n",
    "                       'month_dummy_1', 'rsquared', 'n'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
